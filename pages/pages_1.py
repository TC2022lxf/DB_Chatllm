import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage

st.markdown("# chat_prompt_no_history ğŸ‰")
st.sidebar.markdown("# Page 1 ğŸ‰")
st.sidebar.markdown("## æ²¡æœ‰å†å²è®°å½•ã€æ¯æ¬¡å›ç­”ä¼šæ˜¾ç¤ºæ¥æºä½†ä¸ä¿å­˜")

import pandas as pd
import streamlit as st
import torch
from langchain_community.chat_models import ChatOllama
from langchain_community.llms.ollama import Ollama
from langchain_core.messages import AIMessage, HumanMessage
from utils.retriever import retrievers
from utils.load_data import load_data
from utils.llm import *

llm = ChatOllama(base_url="http://localhost:11434",
                 model=st.session_state.llm,
                 callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))
docsearch = chroma_source().as_retriever()
if 'messages2' not in st.session_state:  # æ£€æŸ¥ st.session_state ä¸­æ˜¯å¦å­˜åœ¨åä¸º 'messages' çš„é”®
    st.session_state['messages2'] = []
messages = st.session_state.get('messages2', [])  # è·å–messages
print(messages)
for message in messages:  # éå†æ¯ä¸€æ¡ä¿¡æ¯
    if isinstance(message, AIMessage):  # æ£€æŸ¥å˜é‡ message æ˜¯å¦æ˜¯ä¸€ä¸ªåä¸º AIMessage çš„ç±»çš„å®ä¾‹ã€‚
        with st.chat_message('assistant'):  # åˆ›å»ºä¸€ä¸ªèŠå¤©æ¶ˆæ¯æ¡†ï¼Œ
            st.markdown(message.content)  # æ¶ˆæ¯å†…å®¹ä»¥ Markdown æ ¼å¼æ˜¾ç¤ºã€‚
    elif isinstance(message, HumanMessage):
        with st.chat_message('user'):  # åˆ›å»ºä¸€ä¸ªuserçš„èŠå¤©æ¶ˆæ¯æ¡†ï¼Œ
            st.markdown(message.content)

if user_input := st.chat_input("Enter your question here"):  # chat_inputåˆ›å»ºèŠå¤©è¾“å…¥æ¡†->user_input
    st.session_state.messages2.append(HumanMessage(content=user_input))  # è¾“å…¥å†…å®¹ä½œä¸ºä¸€ä¸ªHMå¯¹è±¡å®ä¾‹è¢«æ·»åŠ åˆ°st.session_state.messagesåˆ—è¡¨ä¸­
    st.chat_message("user").markdown(user_input)  # æ˜¾ç¤ºç”¨æˆ·åˆšåˆšè¾“å…¥çš„é—®é¢˜ï¼Œæ ‡è®°ä¸ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("assistant"):  # ä¸‹é¢çš„ä»£ç ç”Ÿæˆllmçš„å›ç­”->assistant
        chain = load_qa_chain(llm, chain_type="stuff", prompt=prompt1())
        docs = docsearch.get_relevant_documents(user_input)
        result=chain({"input_documents": docs, "question": user_input}, return_only_outputs=True)
        st.markdown("## ç­”æ¡ˆæ¥æºï¼š")
        st.markdown(docs)
        st.markdown("## ç­”æ¡ˆï¼š")
        st.markdown(result["output_text"])
    st.session_state.messages2.append(AIMessage(content=result["output_text"]))